{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21fa7ea",
   "metadata": {},
   "source": [
    "# Hand Gesture Recognition - Model Training and Evaluation\n",
    "## Building CNN and CNN+LSTM Models\n",
    "\n",
    "This notebook covers:\n",
    "- Preprocessing collected data\n",
    "- Building CNN model for static gesture recognition\n",
    "- Building CNN+LSTM model for temporal gesture recognition\n",
    "- Training with proper validation and callbacks\n",
    "- Evaluating model performance\n",
    "- Visualizing results with confusion matrices and training history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5402f8a9",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67848294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "sys.path.insert(0, str(Path('../').resolve()))\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress TF warnings\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check TensorFlow version\n",
    "print(f\"✓ TensorFlow version: {tf.__version__}\")\n",
    "print(f\"✓ GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31e0862",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d4459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import HandPreprocessor, load_dataset, save_dataset\n",
    "\n",
    "# Preprocess raw data\n",
    "print(\"Loading and preprocessing dataset...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "preprocessor = HandPreprocessor(image_size=(224, 224))\n",
    "\n",
    "try:\n",
    "    # Try to load preprocessed dataset\n",
    "    X_train, X_test, y_train, y_test, class_names, class_to_idx = load_dataset('../data/processed/dataset.pkl')\n",
    "    print(\"✓ Preprocessed dataset loaded from cache\")\n",
    "except FileNotFoundError:\n",
    "    # Preprocess from raw data\n",
    "    print(\"Preprocessing raw data...\")\n",
    "    X_train, X_test, y_train, y_test, class_names, class_to_idx = \\\n",
    "        preprocessor.load_dataset_from_directory('../data/raw', augment=True, test_split=0.2)\n",
    "    \n",
    "    # Save for future use\n",
    "    save_dataset(X_train, X_test, y_train, y_test, class_names, class_to_idx)\n",
    "\n",
    "# Split train into train and validation\n",
    "split_idx = int(len(X_train) * 0.8)\n",
    "X_val = X_train[split_idx:]\n",
    "y_val = y_train[split_idx:]\n",
    "X_train = X_train[:split_idx]\n",
    "y_train = y_train[:split_idx]\n",
    "\n",
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"  Classes: {class_names}\")\n",
    "print(f\"  Training: {len(X_train)} samples\")\n",
    "print(f\"  Validation: {len(X_val)} samples\")\n",
    "print(f\"  Test: {len(X_test)} samples\")\n",
    "print(f\"  Input shape: {X_train[0].shape}\")\n",
    "print(f\"  Label range: {y_train.min()} - {y_train.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2514696",
   "metadata": {},
   "source": [
    "## 3. Build CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9526c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import create_simple_cnn_model, GestureRecognitionCNN\n",
    "\n",
    "# Create a simple CNN model\n",
    "print(\"Building CNN Model...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "model_cnn = create_simple_cnn_model(num_classes=len(class_names))\n",
    "\n",
    "# Compile model\n",
    "model_cnn.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy(name='accuracy'),\n",
    "        keras.metrics.SparseTopKCategoricalAccuracy(k=2, name='top_2_accuracy')\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"✓ Model compiled successfully\")\n",
    "print(f\"✓ Total parameters: {model_cnn.count_params():,}\")\n",
    "\n",
    "# Show model architecture\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95605292",
   "metadata": {},
   "source": [
    "## 4. Train CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c19e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        '../models/best_cnn_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=0\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train model\n",
    "print(\"Training CNN Model...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "history_cnn = model_cnn.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8d9726",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443936ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating Model on Test Set...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "test_loss, test_accuracy, test_top2 = model_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Top-2 Accuracy: {test_top2:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "y_pred_probs = model_cnn.predict(X_test, verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "# Visualize training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history_cnn.history['accuracy'], label='Training', linewidth=2)\n",
    "axes[0].plot(history_cnn.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=11, fontweight='bold')\n",
    "axes[0].set_ylabel('Accuracy', fontsize=11, fontweight='bold')\n",
    "axes[0].set_title('Model Accuracy', fontsize=12, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history_cnn.history['loss'], label='Training', linewidth=2)\n",
    "axes[1].plot(history_cnn.history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=11, fontweight='bold')\n",
    "axes[1].set_ylabel('Loss', fontsize=11, fontweight='bold')\n",
    "axes[1].set_title('Model Loss', fontsize=12, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=class_names,\n",
    "           yticklabels=class_names,\n",
    "           cbar_kws={'label': 'Count'},\n",
    "           annot_kws={'size': 12, 'weight': 'bold'})\n",
    "plt.xlabel('Predicted Label', fontsize=11, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=11, fontweight='bold')\n",
    "plt.title('Confusion Matrix - Test Set', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e22a9d",
   "metadata": {},
   "source": [
    "## 6. Prediction Visualization with Confidence Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions with confidence scores\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Select 15 random test samples\n",
    "sample_indices = np.random.choice(len(X_test), 15, replace=False)\n",
    "\n",
    "for idx, sample_idx in enumerate(sample_indices):\n",
    "    # Get image and prediction\n",
    "    image = X_test[sample_idx]\n",
    "    true_label = y_test[sample_idx]\n",
    "    pred_label = y_pred[sample_idx]\n",
    "    confidence = y_pred_probs[sample_idx][pred_label]\n",
    "    \n",
    "    # Display image\n",
    "    axes[idx].imshow(image)\n",
    "    axes[idx].axis('off')\n",
    "    \n",
    "    # Set title with prediction info\n",
    "    true_name = class_names[true_label]\n",
    "    pred_name = class_names[pred_label]\n",
    "    \n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    title = f\"True: {true_name}\\nPred: {pred_name}\\nConf: {confidence:.2%}\"\n",
    "    axes[idx].set_title(title, fontsize=9, fontweight='bold', color=color)\n",
    "\n",
    "plt.suptitle('Sample Predictions with Confidence Scores', fontsize=13, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Per-class accuracy\n",
    "print(\"\\nPer-Class Accuracy:\")\n",
    "print(\"-\" * 40)\n",
    "for class_idx, class_name in enumerate(class_names):\n",
    "    class_mask = y_test == class_idx\n",
    "    if class_mask.sum() > 0:\n",
    "        class_accuracy = accuracy_score(y_test[class_mask], y_pred[class_mask])\n",
    "        print(f\"{class_name:15s}: {class_accuracy:.4f} ({int(class_mask.sum())} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab0c98",
   "metadata": {},
   "source": [
    "## 7. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2387d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "model_path = Path('../models/cnn_gesture_model.h5')\n",
    "model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "model_cnn.save(str(model_path))\n",
    "\n",
    "print(f\"✓ Model saved to: {model_path}\")\n",
    "print(f\"  Model size: {model_path.stat().st_size / 1e6:.2f} MB\")\n",
    "\n",
    "# Save class information\n",
    "import json\n",
    "class_info = {\n",
    "    'class_names': class_names,\n",
    "    'class_to_idx': class_to_idx,\n",
    "    'test_accuracy': float(test_accuracy),\n",
    "    'test_loss': float(test_loss)\n",
    "}\n",
    "\n",
    "info_path = Path('../models/cnn_class_info.json')\n",
    "with open(info_path, 'w') as f:\n",
    "    json.dump(class_info, f, indent=2)\n",
    "\n",
    "print(f\"✓ Class information saved to: {info_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
